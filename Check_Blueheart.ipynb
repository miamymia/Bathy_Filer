{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blueheart Tools\n",
    "- Notebook to go through cruise folders on blueheart and do different things, e.g. if grids and/or Qimera projects exist\n",
    "- Note that you need to be connected to Blueheart\n",
    "- Running the bash cells doesn't work (yet), you need to copy the commands in a terminal\n",
    "\n",
    "### Sync folders to local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /Volumes/bathymetry/_blueheart/00_MARIASMERIAN/MERIAN_GEOMAR/MSM75/raw\n",
    "find . -maxdepth 4 -name '*EM122.all' -exec cp -n {} /Users/mschumacher/Docs_Data/Bathy/Processing/MSM75/EM122 \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List dirs without Qimera folder (bash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SONNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR\n",
    "\n",
    "parent_dir=/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR\n",
    "list_dir=/Users/mschumacher/Docs_Data/Bathy/Processing\n",
    "\n",
    "ending=\"_Qimera\"\n",
    "\n",
    "for dir in \"$parent_dir\"/*; do\n",
    "    if [ -d \"$dir\" ]; then\n",
    "        if ! find \"$dir\" -maxdepth 1 -type d -name \"*$ending\" | grep -q .; then\n",
    "            echo \"$dir\" >> \"$list_dir\"/SONNE_qimera_list.txt\n",
    "        fi\n",
    "    fi\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR\n",
    "\n",
    "rm SONNE_grid_list.txt \n",
    "rm SONNE_cruise_list.txt \n",
    "rm SONNE_zero_list.txt \n",
    "rm SONNE_gpkg_list.txt \n",
    "\n",
    "ls */*/_grd/*EPSG3395.tif > SONNE_grid_list.txt \n",
    "ls > SONNE_cruise_list.txt\n",
    "ls */*/_grd/*_zero.tif > SONNE_zero_list.txt\n",
    "ls */*/_grd/*_area.gpkg > SONNE_gpkg_list.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path = '/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/'\n",
    "cruise_list = '/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SONNE_cruise_list.txt'\n",
    "grid_list = '/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SONNE_grid_list.txt'\n",
    "\n",
    "with open(cruise_list, 'r') as c_fi:\n",
    "    cruise_path = c_fi.readlines()\n",
    "    CRUISE = []\n",
    "    for c_path in cruise_path:\n",
    "        cruise = c_path.split('\\n')[0]\n",
    "        CRUISE.append(cruise)\n",
    "with open(grid_list, 'r') as g_fi:\n",
    "    grid_path = g_fi.readlines()\n",
    "    GRID = []\n",
    "    for g_path in grid_path:\n",
    "        #print(os.path.join(path,g_path))\n",
    "        grid = g_path.split('/')[0]\n",
    "        GRID.append(grid)\n",
    "\n",
    "# Compare cruise lists and grid list to evaluate where grids are missing\n",
    "#set(cruise) & set(GRID)\n",
    "#print(set(CRUISE).intersection(GRID))\n",
    "missing_grids = [ cr for cr in CRUISE if cr not in GRID ]\n",
    "print(np.array(missing_grids))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build virtual raster tiles (vrt) and convert to geotiff to merge single files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# separate bands (! caution: very large file!)\n",
    "#gdalbuildvrt -overwrite -separate -input_file_list SONNE_grid_list.txt SONNE_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.vrt\n",
    "#gdal_translate -of GTiff -co \"COMPRESS=DEFLATE\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" SONNE_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.vrt SONNE_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.tif\n",
    "\n",
    "# one band\n",
    "gdalbuildvrt -overwrite -input_file_list SONNE_grid_list.txt SONNE_GEOMAR_AllSoundings_DivRes_EPSG3395.vrt\n",
    "gdal_translate -of GTiff -co \"COMPRESS=DEFLATE\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" SONNE_GEOMAR_AllSoundings_DivRes_EPSG3395.vrt SONNE_GEOMAR_AllSoundings_DivRes_EPSG3395.tif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MERIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd /Volumes/bathymetry/_blueheart/00_MARIASMERIAN/MERIAN_GEOMAR\n",
    "\n",
    "rm MERIAN_grid_list.txt \n",
    "rm MERIAN_cruise_list.txt \n",
    "rm MERIAN_zero_list.txt\n",
    "rm MERIAN_gpkg_list.txt\n",
    "\n",
    "ls */*/_grd/*EPSG3395.tif > MERIAN_grid_list.txt \n",
    "ls > MERIAN_cruise_list.txt\n",
    "ls */*/_grd/*_zero.tif > MERIAN_zero_list.txt\n",
    "ls */*/_grd/*_area.gpkg > MERIAN_gpkg_list.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from osgeo import gdal\n",
    "\n",
    "cruise_list = '/Volumes/bathymetry/_blueheart/00_MARIASMERIAN/MERIAN_GEOMAR/MERIAN_cruise_list.txt'\n",
    "grid_list = '/Volumes/bathymetry/_blueheart/00_MARIASMERIAN/MERIAN_GEOMAR/MERIAN_grid_list.txt'\n",
    "\n",
    "with open(cruise_list, 'r') as c_fi:\n",
    "    cruise_path = c_fi.readlines()\n",
    "    CRUISE = []\n",
    "    for c_path in cruise_path:\n",
    "        cruise = c_path.split('\\n')[0]\n",
    "        CRUISE.append(cruise)\n",
    "with open(grid_list, 'r') as g_fi:\n",
    "    grid_path = g_fi.readlines()\n",
    "    GRID = []\n",
    "    for g_path in grid_path:\n",
    "        grid = g_path.split('/')[0]\n",
    "        #print(grid)\n",
    "        GRID.append(grid)\n",
    "\n",
    "# Compare cruise lists and grid list to evaluate where grids are missing\n",
    "missing_grids = [ cr for cr in CRUISE if cr not in GRID ]\n",
    "#print(len(missing_grids))\n",
    "print(np.array(missing_grids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build virtual raster tiles (vrt) and convert to geotiff to merge single files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#gdal_merge -o METEOR.tif -n 0 -co COMPRESS=DEFLATE -co TILED=YES -co BIGTIFF=YES --optfile METEOR_grid_list.txt \n",
    "\n",
    "# separate bands (! caution: very large file!)\n",
    "#gdalbuildvrt -overwrite -separate -input_file_list MERIAN_grid_list.txt MERIAN_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.vrt\n",
    "#gdal_translate -of GTiff -co \"COMPRESS=DEFLATE\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" MERIAN_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.vrt MERIAN_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.tif\n",
    "\n",
    "# one band\n",
    "gdalbuildvrt -overwrite -input_file_list MERIAN_grid_list.txt MERIAN_GEOMAR_AllSoundings_DivRes_EPSG3395.vrt\n",
    "gdal_translate -of GTiff -co \"COMPRESS=DEFLATE\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" MERIAN_GEOMAR_AllSoundings_DivRes_EPSG3395.vrt MERIAN_GEOMAR_AllSoundings_DivRes_EPSG3395.tif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd  /Volumes/bathymetry/_blueheart/00_METEOR/METEOR_GEOMAR\n",
    "\n",
    "rm METEOR_grid_list.txt \n",
    "rm METEOR_cruise_list.txt \n",
    "rm METEOR_gpkg_list.txt\n",
    "rm METEOR_zero_list.txt\n",
    "\n",
    "ls */*/_grd/*EPSG3395.tif > METEOR_grid_list.txt \n",
    "ls > METEOR_cruise_list.txt\n",
    "ls */*/_grd/*_zero.tif > METEOR_zero_list.txt \n",
    "ls */*/_grd/*_area.gpkg > METEOR_gpkg_list.txt \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cruise_list = '/Volumes/bathymetry/_blueheart/00_METEOR/METEOR_GEOMAR/METEOR_cruise_list.txt'\n",
    "grid_list = '/Volumes/bathymetry/_blueheart/00_METEOR/METEOR_GEOMAR/METEOR_grid_list.txt'\n",
    "\n",
    "with open(cruise_list, 'r') as c_fi:\n",
    "    cruise_path = c_fi.readlines()\n",
    "    CRUISE = []\n",
    "    for c_path in cruise_path:\n",
    "        cruise = c_path.split('\\n')[0]\n",
    "        CRUISE.append(cruise)\n",
    "with open(grid_list, 'r') as g_fi:\n",
    "    grid_path = g_fi.readlines()\n",
    "    GRID = []\n",
    "    for g_path in grid_path:\n",
    "        grid = g_path.split('/')[0]\n",
    "        GRID.append(grid)\n",
    "\n",
    "# Compare cruise lists and grid list to evaluate where grids are missing\n",
    "missing_grids = [ cr for cr in CRUISE if cr not in GRID ]\n",
    "print(len(missing_grids), np.array(missing_grids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create merged grid from single grids and coverage as gpkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#gdal_merge -o METEOR.tif -n 0 -co COMPRESS=DEFLATE -co TILED=YES -co BIGTIFF=YES --optfile METEOR_grid_list.txt \n",
    "# separate bands\n",
    "#gdalbuildvrt -overwrite -separate -input_file_list METEOR_grid_list.txt METEOR_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.vrt\n",
    "#gdal_translate -of GTiff -co \"COMPRESS=DEFLATE\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" METEOR_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.vrt METEOR_GEOMAR_AllSoundings_DivRes_separate_EPSG3395.tif\n",
    "\n",
    "# one band\n",
    "gdalbuildvrt -overwrite -input_file_list METEOR_grid_list.txt METEOR_GEOMAR_AllSoundings_DivRes_EPSG3395.vrt\n",
    "gdal_translate -of GTiff -co \"COMPRESS=DEFLATE\" -co \"TILED=YES\" -co \"BIGTIFF=YES\" METEOR_GEOMAR_AllSoundings_DivRes_EPSG3395.vrt METEOR_GEOMAR_AllSoundings_DivRes_EPSG3395.tif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygonise geotiffs\n",
    "- calculate zero grid from grid list\n",
    "- create list from zero grids\n",
    "- polygonise zero grids to avoid millions of features due to colour change\n",
    "- create list from shape files\n",
    "- remove unneccessary features in shapes (those with '0')\n",
    "- dissolve fields\n",
    "- add field for cruise name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%bash\n",
    "\n",
    "# convert single files\n",
    "\n",
    "ifi=/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SO254/SO254_products/_grd/SO254_EM122_400m_CUBE_A_EPSG3395.tif\n",
    "ofi=/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SO254/SO254_products/_grd/SO254_EM122_400m_CUBE_A_EPSG3395_zero.tif\n",
    "shp=/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SO254/SO254_products/_grd/SO254_EM122_400m_CUBE_A_EPSG3395_area.gpkg\n",
    "gdal_calc.py -A $ifi --outfile=$ofi --co=\"COMPRESS=DEFLATE\" --co=\"TILED=YES\" --calc=\"(A*0)+1\"\n",
    "gdal_polygonize.py $ofi $shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "%%bash\n",
    "cd /Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR\n",
    "\n",
    "# Only uf neccessary: remove earlier versions of zero grids\n",
    "# find . -maxdepth 4 -name '*_zero.tif' -exec rm {} \\;\n",
    "\n",
    "\n",
    "ifi=SONNE_grid_list.txt\n",
    "IFS=$'\\n'       \n",
    "set -f    \n",
    "for f in $(cat < \"$ifi\"); do\n",
    "  gdal_calc.py -A \"$f\" --outfile=\"${f%%.*}_zero.tif\" --calc=\"(A*0)+1\"\n",
    "done\n",
    "\n",
    "# create list from zero grids\n",
    "#find . -name \"*_zero.tif\" > METEOR_zero_list.txt \n",
    "ls */*/_grd/*_zero.tif > SONNE_zero_list.txt \n",
    "\n",
    "# polygonise zero grids to avoid millions of features due to colour change\n",
    "ifi_z=SONNE_zero_list.txt\n",
    "IFS=$'\\n'       \n",
    "set -f          \n",
    "for zf in $(cat < \"$ifi_z\"); do\n",
    "  gdal_polygonize.py \"$zf\" \"${zf%%.*}_area.gpkg\"\n",
    "done\n",
    "\n",
    "# create list from shape files\n",
    "#find . -name \"*_area.gpkg\" > METEOR_gpkg_list.txt\n",
    "ls */*/_grd/*_area.gpkg > SONNE_gpkg_list.txt\n",
    "ls */*/_grd/*_EPSG3395_Area.gpkg > SONNE_gpkg_list.txt\n",
    "\n",
    "# create list from _shp folders\n",
    "#find . type dir -name \"/_shp\" > METEOR_shp_list.txt\n",
    "\n",
    "# copy shape to _shp\n",
    "find . -maxdepth 4 -name '*_Area.gpkg' -exec mv {} SONNE_Cov/ \\;\n",
    "find . -maxdepth 4 -name '*_zero_area.gpkg' -exec rm {} \\;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = \"/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR\"\n",
    "shp_list = \"//Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SONNE_gpkg_list.txt\"\n",
    "grid_list = '/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SONNE_grid_list.txt'\n",
    "with open(grid_list, 'r') as g_fi:\n",
    "    grid_path = g_fi.readlines()\n",
    "with open(shp_list, 'r') as s_fi:\n",
    "    shp_path = s_fi.readlines()\n",
    "    for s_path, g_path in zip(shp_path, grid_path):\n",
    "        shp = os.path.join(path,s_path)\n",
    "        grid = os.path.join(path,g_path)\n",
    "        #shp_df = s_path.split('/')[0]\n",
    "        shp_df = gpd.read_file(shp, index_col = False)\n",
    "        shp_df_red = shp_df.drop(shp_df[shp_df['DN'] == 0].index)\n",
    "        shp_diss = shp_df_red.dissolve(by = 'DN')\n",
    "        shp_diss['Filename'] = os.path.basename(grid)\n",
    "        shp_diss['Area [km2]'] = np.sum(shp_diss['geometry'].area)/(1000*1000)\n",
    "        #out_shp = shp[:-15] + '_area.shp'\n",
    "        out_shp = shp.replace('_zero_area.gpkg', '_Area.gpkg')\n",
    "        print(f'out_shp: {out_shp}')\n",
    "        shp_diss.to_file(out_shp, driver='GPKG', mode='w')\n",
    "        #print(shp_df_red['DN'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove boxes around coverages\n",
    "- find out which DN has to be removed \n",
    "- DN -2147483648 f√ºr Meteor & Sonne\n",
    "- DN 0 for Merian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PurePath\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path_gpkg = Path('/Volumes/bathymetry/_blueheart/00_SONNE/SONNE_GEOMAR/SONNE_Cov')\n",
    "#gpkg = path_gppk.rglob('*.gpkg')\n",
    "for shp in path_gpkg.glob('*.gpkg'):\n",
    "    print(shp)\n",
    "    shp_df = gpd.read_file(shp, index_col = False)\n",
    "    shp_df_red = shp_df.drop(shp_df[shp_df['DN'] == -2147483648].index)\n",
    "    shp_diss = shp_df_red.dissolve(by = 'DN')\n",
    "    #out_shp = shp.replace('*_Area.gpkg', '*_Area_box.gpkg')\n",
    "    out_shp = shp.with_name(f\"{shp.stem.replace('Area','Area_box')}{shp.suffix}\")\n",
    "    print(f'out_shp: {out_shp}')\n",
    "    shp_diss.to_file(out_shp, driver='GPKG', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge gpkg such that only features that contain other values than 0 (mostly 1) \n",
    "%%bash\n",
    "\n",
    "cd /Volumes/bathymetry/_blueheart/00_METEOR/METEOR_GEOMAR\n",
    "mkdir /Volumes/bathymetry/_blueheart/00_METEOR/METEOR_GEOMAR/METEOR_Cov\n",
    "\n",
    "ifi_z=METEOR_gpkg_list.txt\n",
    "IFS=$'\\n'      \n",
    "set -f  \n",
    "for zf in $(cat < \"$ifi_z\"); do\n",
    "  mv \"$zf\" /Volumes/bathymetry/_blueheart/00_METEOR/METEOR_GEOMAR/METEOR_Cov\n",
    "done\n",
    "\n",
    "ogrmerge.py -f GPKG -o SONNE_GEOMAR_TID_EPSG3395.gpkg *_box.gpkg -src_geom_type MULTIPOLYGON\n",
    "ogrmerge.py -f GPKG -o UnchartedSeamounts_Sectors_30.gpkg UnchartedSeamounts_Sector*.gpkg \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".sidescantools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
